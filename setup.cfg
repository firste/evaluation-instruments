[metadata]
name = evaluation-instruments
version = 0.0.2
description = evaluation-instruments: Evaluation instruments for healthcare AI use cases
author = Epic
author_email = OpenSourceContributions-Python@epic.com
license_files = LICENSE.txt
license = BSD 3-Clause
classifiers =
    Programming Language :: Python :: 3
    License :: OSI Approved :: BSD License
    Operating System :: OS Independent
    Intended Audience :: Healthcare Industry
project_urls =
    Source = https://github.com/epic-open-source/evaluation-instruments
readme = file: README.md

[options]
python_requires = >=3.10
zip_safe = false
packages =
    find:
include_package_data = True
install_requires =
    jupyterlab>=4.2.5,<5
    pandas>=2.2,<3
    pydantic>=2.6.3,<3

[options.packages.find]
where = src
include =
    evaluation_instruments
    evaluation_instruments.*

[options.package_data]
evaluation_instruments = instruments/**/*

[options.extras_require]
all =
dev =
    pre-commit>=4.2.0
    pytest>=5.1.1
    coverage>=7.5.1

[tool:pytest]
testpaths = tests
filterwarnings =
    ignore::UserWarning
    ignore::PendingDeprecationWarning

[coverage:run]
branch = True
source =
    evaluation_instruments

[coverage:html]
directory = coverage/html-report

[coverage:xml]
output = coverage/coverage.xml

[tool:isort]
line_length = 119
profile = black

[flake8]
max-line-length = 119
extend-ignore = F821
per-file-ignores =
    # F401 imported but unused
    # F403 wildcard import, unable to detect names
    __init__.py: F401, F403
    # F811 redefinition of unused, fixtures
    tests/*: F811
    # E402 prompt files import after prompts
    # E501 prompts can be whitespace sensitive
    instruments/**/*prompt.py: E402, E501
